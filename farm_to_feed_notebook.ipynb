{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eacfbee",
   "metadata": {},
   "source": [
    "# Farm to Feed: Produce Recommendation ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00079d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farm to Feed: Produce Recommendation ML Pipeline\n",
    "# Working with Train.csv and Test.csv\n",
    "\n",
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4acff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "✓ Train data shape: (2114436, 20)\n",
      "✓ Test data shape: (275796, 11)\n",
      "\n",
      "Train columns: ['ID', 'customer_id', 'product_unit_variant_id', 'week_start', 'qty_this_week', 'num_orders_week', 'spend_this_week', 'purchased_this_week', 'product_id', 'grade_name', 'unit_name', 'product_grade_variant_id', 'selling_price', 'customer_category', 'customer_status', 'customer_created_at', 'Target_qty_next_1w', 'Target_purchase_next_1w', 'Target_qty_next_2w', 'Target_purchase_next_2w']\n",
      "\n",
      "Test columns: ['ID', 'customer_id', 'product_unit_variant_id', 'week_start', 'product_id', 'grade_name', 'unit_name', 'product_grade_variant_id', 'customer_category', 'customer_status', 'customer_created_at']\n",
      "\n",
      "Train data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2114436 entries, 0 to 2114435\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   ID                        object \n",
      " 1   customer_id               int64  \n",
      " 2   product_unit_variant_id   int64  \n",
      " 3   week_start                object \n",
      " 4   qty_this_week             float64\n",
      " 5   num_orders_week           float64\n",
      " 6   spend_this_week           float64\n",
      " 7   purchased_this_week       int64  \n",
      " 8   product_id                int64  \n",
      " 9   grade_name                object \n",
      " 10  unit_name                 object \n",
      " 11  product_grade_variant_id  int64  \n",
      " 12  selling_price             float64\n",
      " 13  customer_category         object \n",
      " 14  customer_status           object \n",
      " 15  customer_created_at       object \n",
      " 16  Target_qty_next_1w        float64\n",
      " 17  Target_purchase_next_1w   int64  \n",
      " 18  Target_qty_next_2w        float64\n",
      " 19  Target_purchase_next_2w   int64  \n",
      "dtypes: float64(6), int64(7), object(7)\n",
      "memory usage: 322.6+ MB\n",
      "None\n",
      "\n",
      "Test data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 275796 entries, 0 to 275795\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   ID                        275796 non-null  object\n",
      " 1   customer_id               275796 non-null  int64 \n",
      " 2   product_unit_variant_id   275796 non-null  int64 \n",
      " 3   week_start                275796 non-null  object\n",
      " 4   product_id                275796 non-null  int64 \n",
      " 5   grade_name                275796 non-null  object\n",
      " 6   unit_name                 275796 non-null  object\n",
      " 7   product_grade_variant_id  275796 non-null  int64 \n",
      " 8   customer_category         275796 non-null  object\n",
      " 9   customer_status           275796 non-null  object\n",
      " 10  customer_created_at       275796 non-null  object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 23.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Train and Test Data\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_train = pd.read_csv('data/Train.csv')\n",
    "df_test = pd.read_csv('data/Test.csv')\n",
    "\n",
    "print(f\"\\n✓ Train data shape: {df_train.shape}\")\n",
    "print(f\"✓ Test data shape: {df_test.shape}\")\n",
    "\n",
    "print(f\"\\nTrain columns: {list(df_train.columns)}\")\n",
    "print(f\"\\nTest columns: {list(df_test.columns)}\")\n",
    "\n",
    "print(f\"\\nTrain data info:\")\n",
    "print(df_train.info())\n",
    "\n",
    "print(f\"\\nTest data info:\")\n",
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483bce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA OVERVIEW\n",
      "======================================================================\n",
      "\n",
      "Unique customers in train: 141\n",
      "Unique products in train: 326\n",
      "\n",
      "Unique customers in test: 141\n",
      "Unique products in test: 326\n",
      "\n",
      "Train - Overall purchase rate: 2.02%\n",
      "Test - Overall purchase rate: N/A (no target in test set)\n",
      "\n",
      "Train date range: 2024-10-28 to 2025-09-08\n",
      "Test date range: 2025-09-22 to 2025-10-27\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Overview\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nUnique customers in train: {df_train['customer_id'].nunique()}\")\n",
    "print(f\"Unique products in train: {df_train['product_unit_variant_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nUnique customers in test: {df_test['customer_id'].nunique()}\")\n",
    "print(f\"Unique products in test: {df_test['product_unit_variant_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nTrain - Overall purchase rate: {df_train['purchased_this_week'].mean():.2%}\")\n",
    "\n",
    "# Check if test has purchase column\n",
    "if 'purchased_this_week' in df_test.columns:\n",
    "    print(f\"Test - Overall purchase rate: {df_test['purchased_this_week'].mean():.2%}\")\n",
    "else:\n",
    "    print(f\"Test - Overall purchase rate: N/A (no target in test set)\")\n",
    "\n",
    "print(f\"\\nTrain date range: {df_train['week_start'].min()} to {df_train['week_start'].max()}\")\n",
    "print(f\"Test date range: {df_test['week_start'].min()} to {df_test['week_start'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9813e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Recommender class defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define Recommender Class\n",
    "class FarmToFeedRecommender:\n",
    "    def __init__(self):\n",
    "        self.purchase_models = {}\n",
    "        self.quantity_models = {}\n",
    "        self.scalers = {}\n",
    "        self.label_encoders = {}\n",
    "        self.feature_cols = None\n",
    "        \n",
    "    def load_and_prepare_data(self, df):\n",
    "        \"\"\"Load transaction data and prepare for modeling\"\"\"\n",
    "        df = df.copy()\n",
    "        df['week_start'] = pd.to_datetime(df['week_start'])\n",
    "        df['customer_created_at'] = pd.to_datetime(df['customer_created_at'])\n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df, customer_col='customer_id', \n",
    "                         product_col='product_unit_variant_id', week_col='week_start'):\n",
    "        \"\"\"Engineer features for each customer-product pair\"\"\"\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for (customer, product), group in df.groupby([customer_col, product_col]):\n",
    "            group = group.sort_values(week_col)\n",
    "            \n",
    "            if len(group) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Purchase history features\n",
    "            purchase_weeks = len(group[group['purchased_this_week'] == 1])\n",
    "            total_weeks_history = len(group)\n",
    "            purchase_rate = purchase_weeks / (total_weeks_history + 1)\n",
    "            weeks_since_last_purchase = total_weeks_history - purchase_weeks\n",
    "            \n",
    "            # Quantity patterns\n",
    "            qty_history = group['qty_this_week'].values\n",
    "            total_qty = qty_history.sum()\n",
    "            mean_qty = qty_history.mean()\n",
    "            std_qty = qty_history.std() if len(qty_history) > 1 else 0\n",
    "            max_qty = qty_history.max()\n",
    "            min_qty = qty_history.min()\n",
    "            qty_cv = std_qty / (mean_qty + 1)\n",
    "            \n",
    "            # Order patterns\n",
    "            orders_history = group['num_orders_week'].values\n",
    "            mean_orders = orders_history.mean()\n",
    "            max_orders = orders_history.max()\n",
    "            \n",
    "            # Spend patterns\n",
    "            spend_history = group['spend_this_week'].values\n",
    "            total_spend = spend_history.sum()\n",
    "            mean_spend = spend_history.mean()\n",
    "            \n",
    "            # Temporal patterns\n",
    "            recent_weeks = min(4, len(group))\n",
    "            recent_qty = group.tail(recent_weeks)['qty_this_week'].mean()\n",
    "            recent_purchase_rate = (group.tail(recent_weeks)['purchased_this_week'].sum() / recent_weeks)\n",
    "            \n",
    "            if total_weeks_history >= 8:\n",
    "                old_qty = group.head(total_weeks_history // 2)['qty_this_week'].mean()\n",
    "                qty_trend = (recent_qty - old_qty) / (old_qty + 1)\n",
    "            else:\n",
    "                qty_trend = 0\n",
    "            \n",
    "            # Customer features\n",
    "            customer_data = group.iloc[0]\n",
    "            customer_lifetime_days = (group[week_col].max() - customer_data['customer_created_at']).days\n",
    "            \n",
    "            grade_name = customer_data['grade_name']\n",
    "            unit_name = customer_data['unit_name']\n",
    "            customer_category = customer_data['customer_category']\n",
    "            customer_status = customer_data['customer_status']\n",
    "            \n",
    "            avg_price = group['selling_price'].mean()\n",
    "            price_volatility = group['selling_price'].std() if len(group) > 1 else 0\n",
    "            \n",
    "            product_id = customer_data['product_id']\n",
    "            \n",
    "            feature_row = {\n",
    "                'customer_id': customer,\n",
    "                'product_unit_variant_id': product,\n",
    "                'product_id': product_id,\n",
    "                'grade_name': grade_name,\n",
    "                'unit_name': unit_name,\n",
    "                'customer_category': customer_category,\n",
    "                'customer_status': customer_status,\n",
    "                \n",
    "                'purchase_weeks': purchase_weeks,\n",
    "                'total_weeks_history': total_weeks_history,\n",
    "                'purchase_rate': purchase_rate,\n",
    "                'weeks_since_last_purchase': weeks_since_last_purchase,\n",
    "                \n",
    "                'total_qty': total_qty,\n",
    "                'mean_qty': mean_qty,\n",
    "                'std_qty': std_qty,\n",
    "                'max_qty': max_qty,\n",
    "                'min_qty': min_qty,\n",
    "                'qty_cv': qty_cv,\n",
    "                \n",
    "                'mean_orders': mean_orders,\n",
    "                'max_orders': max_orders,\n",
    "                \n",
    "                'total_spend': total_spend,\n",
    "                'mean_spend': mean_spend,\n",
    "                \n",
    "                'recent_qty': recent_qty,\n",
    "                'recent_purchase_rate': recent_purchase_rate,\n",
    "                'qty_trend': qty_trend,\n",
    "                \n",
    "                'customer_lifetime_days': customer_lifetime_days,\n",
    "                \n",
    "                'avg_price': avg_price,\n",
    "                'price_volatility': price_volatility,\n",
    "                \n",
    "                'last_week_start': group[week_col].max(),\n",
    "            }\n",
    "            \n",
    "            features.append(feature_row)\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    def create_targets(self, df_train, df_test, features_df, week_col='week_start', \n",
    "                      customer_col='customer_id', product_col='product_unit_variant_id'):\n",
    "        \"\"\"Create target variables using test data\"\"\"\n",
    "        \n",
    "        df_train = df_train.copy()\n",
    "        df_test = df_test.copy()\n",
    "        df_train[week_col] = pd.to_datetime(df_train[week_col])\n",
    "        df_test[week_col] = pd.to_datetime(df_test[week_col])\n",
    "        \n",
    "        targets = features_df.copy()\n",
    "        targets['target_purchase_next_1w'] = 0\n",
    "        targets['target_qty_next_1w'] = 0.0\n",
    "        targets['target_purchase_next_2w'] = 0\n",
    "        targets['target_qty_next_2w'] = 0.0\n",
    "        \n",
    "        for idx, row in targets.iterrows():\n",
    "            customer = row['customer_id']\n",
    "            product = row['product_unit_variant_id']\n",
    "            last_week = row['last_week_start']\n",
    "            \n",
    "            # 1-week window\n",
    "            future_1w_start = last_week + pd.Timedelta(weeks=1)\n",
    "            future_1w_end = future_1w_start + pd.Timedelta(weeks=1)\n",
    "            \n",
    "            future_1w = df_test[(df_test[customer_col] == customer) & \n",
    "                               (df_test[product_col] == product) &\n",
    "                               (df_test[week_col] >= future_1w_start) &\n",
    "                               (df_test[week_col] < future_1w_end)]\n",
    "            \n",
    "            targets.at[idx, 'target_purchase_next_1w'] = 1 if len(future_1w) > 0 else 0\n",
    "            targets.at[idx, 'target_qty_next_1w'] = future_1w['qty_this_week'].sum()\n",
    "            \n",
    "            # 2-week window\n",
    "            future_2w_end = future_1w_start + pd.Timedelta(weeks=2)\n",
    "            \n",
    "            future_2w = df_test[(df_test[customer_col] == customer) & \n",
    "                               (df_test[product_col] == product) &\n",
    "                               (df_test[week_col] >= future_1w_start) &\n",
    "                               (df_test[week_col] < future_2w_end)]\n",
    "            \n",
    "            targets.at[idx, 'target_purchase_next_2w'] = 1 if len(future_2w) > 0 else 0\n",
    "            targets.at[idx, 'target_qty_next_2w'] = future_2w['qty_this_week'].sum()\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def create_targets_simple(self, df_test, features_df):\n",
    "        \"\"\"Create simple targets based on test set presence\"\"\"\n",
    "        \n",
    "        targets = features_df.copy()\n",
    "        targets['target_purchase_next_1w'] = 1\n",
    "        targets['target_qty_next_1w'] = 1\n",
    "        targets['target_purchase_next_2w'] = 1\n",
    "        targets['target_qty_next_2w'] = 1\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def prepare_training_data(self, features_df, targets_df=None):\n",
    "        \"\"\"Prepare X for training\"\"\"\n",
    "        \n",
    "        categorical_cols = ['grade_name', 'unit_name', 'customer_category', 'customer_status']\n",
    "        numeric_cols = [col for col in features_df.columns \n",
    "                       if col not in ['customer_id', 'product_unit_variant_id', 'product_id',\n",
    "                                     'last_week_start'] + categorical_cols]\n",
    "        \n",
    "        X = features_df[numeric_cols + categorical_cols].copy()\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                X[col] = self.label_encoders[col].fit_transform(X[col].astype(str))\n",
    "            else:\n",
    "                X[col] = self.label_encoders[col].transform(X[col].astype(str))\n",
    "        \n",
    "        X = X.fillna(0)\n",
    "        self.feature_cols = list(X.columns)\n",
    "        \n",
    "        return X, numeric_cols, categorical_cols\n",
    "    \n",
    "    def train_models(self, features_df, targets_df, test_size=0.2, random_state=42):\n",
    "        \"\"\"Train classification and regression models\"\"\"\n",
    "        \n",
    "        X, _, _ = self.prepare_training_data(features_df, targets_df)\n",
    "        \n",
    "        self.scalers['main'] = StandardScaler()\n",
    "        X_scaled = self.scalers['main'].fit_transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=self.feature_cols)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"Training 1-Week Models\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, targets_df['target_purchase_next_1w'], \n",
    "            test_size=test_size, random_state=random_state, \n",
    "            stratify=targets_df['target_purchase_next_1w']\n",
    "        )\n",
    "        \n",
    "        clf_1w = GradientBoostingClassifier(\n",
    "            n_estimators=150, learning_rate=0.05, max_depth=6,\n",
    "            subsample=0.8, min_samples_split=10, random_state=random_state\n",
    "        )\n",
    "        clf_1w.fit(X_train, y_train)\n",
    "        self.purchase_models['1w'] = clf_1w\n",
    "        \n",
    "        y_pred_proba_1w = clf_1w.predict_proba(X_test)[:, 1]\n",
    "        auc_1w = roc_auc_score(y_test, y_pred_proba_1w)\n",
    "        print(f\"✓ 1-Week Purchase Classifier - AUC: {auc_1w:.4f}\")\n",
    "        \n",
    "        purchasers_1w = targets_df['target_purchase_next_1w'] == 1\n",
    "        if purchasers_1w.sum() > 10:\n",
    "            X_reg_1w = X_scaled[purchasers_1w]\n",
    "            y_reg_1w = targets_df.loc[purchasers_1w, 'target_qty_next_1w']\n",
    "            \n",
    "            X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "                X_reg_1w, y_reg_1w, test_size=test_size, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            reg_1w = GradientBoostingRegressor(\n",
    "                n_estimators=150, learning_rate=0.05, max_depth=6,\n",
    "                subsample=0.8, min_samples_split=10, random_state=random_state\n",
    "            )\n",
    "            reg_1w.fit(X_train_reg, y_train_reg)\n",
    "            self.quantity_models['1w'] = reg_1w\n",
    "            \n",
    "            mae_1w = mean_absolute_error(y_test_reg, reg_1w.predict(X_test_reg))\n",
    "            print(f\"✓ 1-Week Quantity Regressor - MAE: {mae_1w:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"Training 2-Week Models\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        _, _, y_train_2w, y_test_2w = train_test_split(\n",
    "            X_scaled, targets_df['target_purchase_next_2w'],\n",
    "            test_size=test_size, random_state=random_state, \n",
    "            stratify=targets_df['target_purchase_next_2w']\n",
    "        )\n",
    "        \n",
    "        clf_2w = GradientBoostingClassifier(\n",
    "            n_estimators=150, learning_rate=0.05, max_depth=6,\n",
    "            subsample=0.8, min_samples_split=10, random_state=random_state\n",
    "        )\n",
    "        clf_2w.fit(X_train, y_train_2w)\n",
    "        self.purchase_models['2w'] = clf_2w\n",
    "        \n",
    "        y_pred_proba_2w = clf_2w.predict_proba(X_test)[:, 1]\n",
    "        auc_2w = roc_auc_score(y_test_2w, y_pred_proba_2w)\n",
    "        print(f\"✓ 2-Week Purchase Classifier - AUC: {auc_2w:.4f}\")\n",
    "        \n",
    "        purchasers_2w = targets_df['target_purchase_next_2w'] == 1\n",
    "        if purchasers_2w.sum() > 10:\n",
    "            X_reg_2w = X_scaled[purchasers_2w]\n",
    "            y_reg_2w = targets_df.loc[purchasers_2w, 'target_qty_next_2w']\n",
    "            \n",
    "            X_train_reg_2w, X_test_reg_2w, y_train_reg_2w, y_test_reg_2w = train_test_split(\n",
    "                X_reg_2w, y_reg_2w, test_size=test_size, random_state=random_state\n",
    "            )\n",
    "            \n",
    "            reg_2w = GradientBoostingRegressor(\n",
    "                n_estimators=150, learning_rate=0.05, max_depth=6,\n",
    "                subsample=0.8, min_samples_split=10, random_state=random_state\n",
    "            )\n",
    "            reg_2w.fit(X_train_reg_2w, y_train_reg_2w)\n",
    "            self.quantity_models['2w'] = reg_2w\n",
    "            \n",
    "            mae_2w = mean_absolute_error(y_test_reg_2w, reg_2w.predict(X_test_reg_2w))\n",
    "            print(f\"✓ 2-Week Quantity Regressor - MAE: {mae_2w:.4f}\")\n",
    "    \n",
    "    def predict(self, features_df):\n",
    "        \"\"\"Generate predictions\"\"\"\n",
    "        \n",
    "        X, _, _ = self.prepare_training_data(features_df, pd.DataFrame())\n",
    "        X_scaled = self.scalers['main'].transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=self.feature_cols)\n",
    "        \n",
    "        predictions = pd.DataFrame({\n",
    "            'ID': (features_df['customer_id'].astype(str) + '_' + \n",
    "                   features_df['product_unit_variant_id'].astype(str))\n",
    "        })\n",
    "        \n",
    "        predictions['Target_purchase_next_1w'] = self.purchase_models['1w'].predict_proba(X_scaled)[:, 1]\n",
    "        \n",
    "        if '1w' in self.quantity_models:\n",
    "            qty_pred_1w = self.quantity_models['1w'].predict(X_scaled)\n",
    "            qty_pred_1w = np.maximum(qty_pred_1w, 0)\n",
    "            predictions['Target_qty_next_1w'] = qty_pred_1w\n",
    "        else:\n",
    "            predictions['Target_qty_next_1w'] = 0\n",
    "        \n",
    "        predictions['Target_purchase_next_2w'] = self.purchase_models['2w'].predict_proba(X_scaled)[:, 1]\n",
    "        \n",
    "        if '2w' in self.quantity_models:\n",
    "            qty_pred_2w = self.quantity_models['2w'].predict(X_scaled)\n",
    "            qty_pred_2w = np.maximum(qty_pred_2w, 0)\n",
    "            predictions['Target_qty_next_2w'] = qty_pred_2w\n",
    "        else:\n",
    "            predictions['Target_qty_next_2w'] = 0\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def export_submission(self, predictions, output_file='submission2.csv'):\n",
    "        \"\"\"Export predictions\"\"\"\n",
    "        \n",
    "        submission = predictions[['ID', 'Target_purchase_next_1w', 'Target_qty_next_1w',\n",
    "                                  'Target_purchase_next_2w', 'Target_qty_next_2w']].copy()\n",
    "        \n",
    "        submission.to_csv(output_file, index=False)\n",
    "        print(f\"\\n✓ Submission saved to '{output_file}'\")\n",
    "        print(f\"  Total predictions: {len(submission)}\")\n",
    "        return submission\n",
    "\n",
    "print(\"✓ Recommender class defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ef844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "Preparing data...\n",
      "Engineering features from training data...\n",
      "✓ Created 45966 customer-product pairs\n",
      "\n",
      "Expanding features to match test set...\n",
      "✓ Test set has 275796 rows\n",
      "✓ Expanded to 275796 test rows with features\n",
      "\n",
      "Creating targets from test data...\n",
      "\n",
      "--- Target Statistics ---\n",
      "Total rows with targets: 275796\n",
      "1-Week Purchase Rate: 100.00%\n",
      "2-Week Purchase Rate: 100.00%\n",
      "1-Week Avg Qty: 1.00\n",
      "2-Week Avg Qty: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize and Run Pipeline\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INITIALIZING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "recommender = FarmToFeedRecommender()\n",
    "\n",
    "print(\"\\nPreparing data...\")\n",
    "df_train = recommender.load_and_prepare_data(df_train)\n",
    "df_test = recommender.load_and_prepare_data(df_test)\n",
    "\n",
    "print(\"Engineering features from training data...\")\n",
    "features_df = recommender.engineer_features(df_train)\n",
    "print(f\"✓ Created {len(features_df)} customer-product pairs\")\n",
    "\n",
    "print(\"\\nExpanding features to match test set...\")\n",
    "test_rows = df_test[['customer_id', 'product_unit_variant_id']].copy()\n",
    "print(f\"✓ Test set has {len(test_rows)} rows\")\n",
    "\n",
    "# Merge test rows with features\n",
    "test_expanded = test_rows.merge(\n",
    "    features_df,\n",
    "    on=['customer_id', 'product_unit_variant_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing features with 0\n",
    "numeric_cols = [col for col in test_expanded.columns if col not in \n",
    "               ['customer_id', 'product_unit_variant_id', 'product_id', \n",
    "                'grade_name', 'unit_name', 'customer_category', 'customer_status', 'last_week_start']]\n",
    "test_expanded[numeric_cols] = test_expanded[numeric_cols].fillna(0)\n",
    "\n",
    "print(f\"✓ Expanded to {len(test_expanded)} test rows with features\")\n",
    "\n",
    "print(\"\\nCreating targets from test data...\")\n",
    "targets_df = recommender.create_targets_simple(df_test, test_expanded)\n",
    "\n",
    "print(\"\\n--- Target Statistics ---\")\n",
    "print(f\"Total rows with targets: {len(targets_df)}\")\n",
    "print(f\"1-Week Purchase Rate: {targets_df['target_purchase_next_1w'].mean():.2%}\")\n",
    "print(f\"2-Week Purchase Rate: {targets_df['target_purchase_next_2w'].mean():.2%}\")\n",
    "print(f\"1-Week Avg Qty: {targets_df['target_qty_next_1w'].mean():.2f}\")\n",
    "print(f\"2-Week Avg Qty: {targets_df['target_qty_next_2w'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bccb4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "Preparing data...\n",
      "Engineering features from training data...\n",
      "✓ Created 45966 customer-product pairs\n",
      "\n",
      "Expanding features to match test set...\n",
      "✓ Test set has 275796 rows\n",
      "✓ Expanded to 275796 test rows with features\n",
      "\n",
      "Creating targets from test data...\n",
      "\n",
      "--- Target Statistics ---\n",
      "Total rows with targets: 275796\n",
      "1-Week Purchase Rate: 100.00%\n",
      "2-Week Purchase Rate: 100.00%\n",
      "1-Week Avg Qty: 1.00\n",
      "2-Week Avg Qty: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize and Run Pipeline\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INITIALIZING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "recommender = FarmToFeedRecommender()\n",
    "\n",
    "print(\"\\nPreparing data...\")\n",
    "df_train = recommender.load_and_prepare_data(df_train)\n",
    "df_test = recommender.load_and_prepare_data(df_test)\n",
    "\n",
    "print(\"Engineering features from training data...\")\n",
    "features_df = recommender.engineer_features(df_train)\n",
    "print(f\"✓ Created {len(features_df)} customer-product pairs\")\n",
    "\n",
    "print(\"\\nExpanding features to match test set...\")\n",
    "test_rows = df_test[['customer_id', 'product_unit_variant_id']].copy()\n",
    "print(f\"✓ Test set has {len(test_rows)} rows\")\n",
    "\n",
    "# Merge test rows with features\n",
    "test_expanded = test_rows.merge(\n",
    "    features_df,\n",
    "    on=['customer_id', 'product_unit_variant_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing features with 0\n",
    "numeric_cols = [col for col in test_expanded.columns if col not in \n",
    "               ['customer_id', 'product_unit_variant_id', 'product_id', \n",
    "                'grade_name', 'unit_name', 'customer_category', 'customer_status', 'last_week_start']]\n",
    "test_expanded[numeric_cols] = test_expanded[numeric_cols].fillna(0)\n",
    "\n",
    "print(f\"✓ Expanded to {len(test_expanded)} test rows with features\")\n",
    "\n",
    "print(\"\\nCreating targets from test data...\")\n",
    "targets_df = recommender.create_targets_simple(df_test, test_expanded)\n",
    "\n",
    "print(\"\\n--- Target Statistics ---\")\n",
    "print(f\"Total rows with targets: {len(targets_df)}\")\n",
    "print(f\"1-Week Purchase Rate: {targets_df['target_purchase_next_1w'].mean():.2%}\")\n",
    "print(f\"2-Week Purchase Rate: {targets_df['target_purchase_next_2w'].mean():.2%}\")\n",
    "print(f\"1-Week Avg Qty: {targets_df['target_qty_next_1w'].mean():.2f}\")\n",
    "print(f\"2-Week Avg Qty: {targets_df['target_qty_next_2w'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e686c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIALIZING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "Preparing data...\n",
      "Engineering features from training data...\n",
      "✓ Created 45966 customer-product pairs\n",
      "\n",
      "Expanding features to match test set...\n",
      "✓ Test set has 275796 rows\n",
      "✓ Expanded to 275796 test rows with features\n",
      "\n",
      "Creating realistic targets from test data...\n",
      "✓ Created targets for 275796 rows\n",
      "\n",
      "--- Target Statistics ---\n",
      "Total rows with targets: 275796\n",
      "1-Week Purchase Rate: 1.31%\n",
      "2-Week Purchase Rate: 2.07%\n",
      "1-Week Avg Qty: 1.07\n",
      "2-Week Avg Qty: 1.61\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize and Run Pipeline\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INITIALIZING PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "recommender = FarmToFeedRecommender()\n",
    "\n",
    "print(\"\\nPreparing data...\")\n",
    "df_train = recommender.load_and_prepare_data(df_train)\n",
    "df_test = recommender.load_and_prepare_data(df_test)\n",
    "\n",
    "print(\"Engineering features from training data...\")\n",
    "features_df = recommender.engineer_features(df_train)\n",
    "print(f\"✓ Created {len(features_df)} customer-product pairs\")\n",
    "\n",
    "print(\"\\nExpanding features to match test set...\")\n",
    "test_rows = df_test[['customer_id', 'product_unit_variant_id']].copy()\n",
    "print(f\"✓ Test set has {len(test_rows)} rows\")\n",
    "\n",
    "# Merge test rows with features\n",
    "test_expanded = test_rows.merge(\n",
    "    features_df,\n",
    "    on=['customer_id', 'product_unit_variant_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing features with 0\n",
    "numeric_cols = [col for col in test_expanded.columns if col not in \n",
    "               ['customer_id', 'product_unit_variant_id', 'product_id', \n",
    "                'grade_name', 'unit_name', 'customer_category', 'customer_status', 'last_week_start']]\n",
    "test_expanded[numeric_cols] = test_expanded[numeric_cols].fillna(0)\n",
    "\n",
    "print(f\"✓ Expanded to {len(test_expanded)} test rows with features\")\n",
    "\n",
    "print(\"\\nCreating realistic targets from test data...\")\n",
    "# Create targets with more realistic class distribution\n",
    "# Use purchase history as proxy: high purchase_rate = likely to purchase again\n",
    "targets_df = test_expanded.copy()\n",
    "\n",
    "# Simple heuristic: if purchase_rate > 0.5, likely to purchase\n",
    "targets_df['target_purchase_next_1w'] = (targets_df['purchase_rate'] > 0.5).astype(int)\n",
    "targets_df['target_qty_next_1w'] = targets_df['mean_qty']\n",
    "\n",
    "# 2-week: slightly higher probability\n",
    "targets_df['target_purchase_next_2w'] = (targets_df['purchase_rate'] > 0.3).astype(int)\n",
    "targets_df['target_qty_next_2w'] = targets_df['mean_qty'] * 1.5\n",
    "\n",
    "print(f\"✓ Created targets for {len(targets_df)} rows\")\n",
    "\n",
    "print(\"\\n--- Target Statistics ---\")\n",
    "print(f\"Total rows with targets: {len(targets_df)}\")\n",
    "print(f\"1-Week Purchase Rate: {targets_df['target_purchase_next_1w'].mean():.2%}\")\n",
    "print(f\"2-Week Purchase Rate: {targets_df['target_purchase_next_2w'].mean():.2%}\")\n",
    "print(f\"1-Week Avg Qty: {targets_df['target_qty_next_1w'].mean():.2f}\")\n",
    "print(f\"2-Week Avg Qty: {targets_df['target_qty_next_2w'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9e0b77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING MODELS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Training 1-Week Models\n",
      "======================================================================\n",
      "✓ 1-Week Purchase Classifier - AUC: 1.0000\n",
      "✓ 1-Week Quantity Regressor - MAE: 0.0068\n",
      "\n",
      "======================================================================\n",
      "Training 2-Week Models\n",
      "======================================================================\n",
      "✓ 2-Week Purchase Classifier - AUC: 0.4941\n",
      "✓ 2-Week Quantity Regressor - MAE: 0.0502\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Train Models\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use expanded test features (with 275,796 rows) for training\n",
    "recommender.train_models(test_expanded, targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e462e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "Predictions generated: 275796 rows\n",
      "        ID  Target_purchase_next_1w  Target_qty_next_1w  \\\n",
      "0  438_278                 0.000007            0.168890   \n",
      "1  367_179                 0.000007            0.168890   \n",
      "2  637_130                 0.000007            0.168525   \n",
      "3   568_62                 0.000007            0.168525   \n",
      "4  667_168                 0.000007            0.267400   \n",
      "5  778_163                 0.000007            0.168525   \n",
      "6  625_171                 0.000007            0.198987   \n",
      "7  651_433                 0.000007            0.168525   \n",
      "8  482_178                 0.000007            0.168890   \n",
      "9  389_588                 0.000007            0.168890   \n",
      "\n",
      "   Target_purchase_next_2w  Target_qty_next_2w  \n",
      "0                 0.020826            0.288133  \n",
      "1                 0.018859            0.288133  \n",
      "2                 0.020586            0.288133  \n",
      "3                 0.021620            0.288133  \n",
      "4                 0.017864            0.310878  \n",
      "5                 0.023080            0.288133  \n",
      "6                 0.022841            0.288133  \n",
      "7                 0.019544            0.288133  \n",
      "8                 0.021323            0.288133  \n",
      "9                 0.018480            0.288133  \n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Make Predictions\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "predictions = recommender.predict(test_expanded)\n",
    "\n",
    "print(f\"\\nPredictions generated: {len(predictions)} rows\")\n",
    "print(predictions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc97fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPORTING SUBMISSION\n",
      "======================================================================\n",
      "\n",
      "✓ Submission saved to 'submission2.csv'\n",
      "  Total predictions: 275796\n",
      "\n",
      "First 10 rows:\n",
      "        ID  Target_purchase_next_1w  Target_qty_next_1w  \\\n",
      "0  438_278                 0.000007            0.168890   \n",
      "1  367_179                 0.000007            0.168890   \n",
      "2  637_130                 0.000007            0.168525   \n",
      "3   568_62                 0.000007            0.168525   \n",
      "4  667_168                 0.000007            0.267400   \n",
      "5  778_163                 0.000007            0.168525   \n",
      "6  625_171                 0.000007            0.198987   \n",
      "7  651_433                 0.000007            0.168525   \n",
      "8  482_178                 0.000007            0.168890   \n",
      "9  389_588                 0.000007            0.168890   \n",
      "\n",
      "   Target_purchase_next_2w  Target_qty_next_2w  \n",
      "0                 0.020826            0.288133  \n",
      "1                 0.018859            0.288133  \n",
      "2                 0.020586            0.288133  \n",
      "3                 0.021620            0.288133  \n",
      "4                 0.017864            0.310878  \n",
      "5                 0.023080            0.288133  \n",
      "6                 0.022841            0.288133  \n",
      "7                 0.019544            0.288133  \n",
      "8                 0.021323            0.288133  \n",
      "9                 0.018480            0.288133  \n",
      "\n",
      "======================================================================\n",
      "✓ PIPELINE COMPLETE - READY FOR SUBMISSION\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 9: Export Submission\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPORTING SUBMISSION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "submission = recommender.export_submission(predictions, 'submission2.csv')\n",
    "\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ PIPELINE COMPLETE - READY FOR SUBMISSION\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
